{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harithmote98/harith_INFO5731_Fall2021/blob/main/In_class_exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmcQdpqyPKEx"
      },
      "source": [
        "## The third In-class-exercise (9/15/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5L4oYePPKE2"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKON70AnPKE2"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afL_br5bPKE3"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        " Business problem-As flight delays are dependent on a huge number of factors, an intelligent system can be applied to analyze huge data sets in real time to \n",
        " predict delays and re-book customers’ flights in time.\n",
        "Business objective: maxmize customer convenience\n",
        "Business constraint: minimize delays\n",
        "Step-1:\n",
        "As flight delays is a major concern for many people who want to reach the destination on time.Minimizing that effect would benefit people to reach on time\n",
        "For any business problem we have list of particular features.For this business problem we can collect the data such as flight number,date of travelling,\n",
        "place of destination,passenger details,next flight to same destination details,weather conditions,passenger loads,airport capacity.etc,.\n",
        "step-2 :\n",
        "After collecting the data we need to preprocess the data into structured format so that our machine learning can understand and give best suitable results.\n",
        "step-3:People tried with old regression method but didnt worked well due to huge massive data and then switched to deep learning to deal with this particular\n",
        "problem.There are two methods,one is autoencoder and Levenberg-marquart algorithm is applied to and bias proper values.\n",
        "step-4:Then we perform model evaluation, we calculate accuracy,precision,recall and sensitvity.therefore which model gives best suitable results will go with that.\n",
        "step-5:Finally we perform model deployment like into which software we are generating this model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_sjJwygPKE4"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 reviews of a movie from IMDB (https://www.imdb.com/) or 1000 reviews of a product from Amazon (https://www.amazon.com/).\n",
        "\n",
        "As for the IMDB movie review, the following informtion need to be collected (for example: https://www.imdb.com/title/tt6751668/reviews?ref_=tt_urv):\n",
        "\n",
        "(1) User name\n",
        "\n",
        "(2) Star\n",
        "\n",
        "(3) Review title\n",
        "\n",
        "(4) Review text\n",
        "\n",
        "(5) Review posted time\n",
        "\n",
        "\n",
        "As for the Amazon product review, the following information need to be collected (for example: https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=sr_1_3?crid=2E3C55VKJX0K3&dchild=1&keywords=machine+learning+andrew+ng&qid=1631718619&sr=8-3):\n",
        "\n",
        "(1) User name\n",
        "\n",
        "(2) Star\n",
        "\n",
        "(3) Review title\n",
        "\n",
        "(4) Review text\n",
        "\n",
        "(5) Review posted time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JkXPwLnKSkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d150ba1-4b92-410e-eaef-94a289315481"
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease 54.7 kB/88.7 kB 62%] [Connecting to security.ubuntu.com (91.189\r0% [1 InRelease gpgv 242 kB] [2 InRelease 63.4 kB/88.7 kB 71%] [Connecting to s\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [6 InRelease 20.0 kB/74.6 kB 27%] [Connecting to s\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,761 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Get:18 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.4 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,326 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Fetched 11.8 MB in 3s (4,621 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 56 not upgraded.\n",
            "Need to get 91.8 MB of archives.\n",
            "After this operation, 315 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 92.0.4515.159-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 92.0.4515.159-0ubuntu0.18.04.1 [81.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 92.0.4515.159-0ubuntu0.18.04.1 [4,026 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 92.0.4515.159-0ubuntu0.18.04.1 [4,902 kB]\n",
            "Fetched 91.8 MB in 1s (63.8 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155013 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_92.0.4515.159-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[K     |████████████████████████████████| 904 kB 16.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xa1vImJpfYS"
      },
      "source": [
        "from selenium import webdriver #importing selenium package\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "2Slu-iElpgyn",
        "outputId": "5d85c12e-06e8-4932-fb99-c9e40d672db1"
      },
      "source": [
        "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver',options=options) #creating a driver path\n",
        "link = 'https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv'\n",
        "title_array = [] \n",
        "review_array = []\n",
        "driver.get(link)\n",
        "for num in range(43): #giving range 43 to get 1000 reviews\n",
        "  driver.find_element_by_class_name(\"ipl-load-more__button\").click() #giving class name as ipl-load-mote__button to get all pages\n",
        "  time.sleep(5)\n",
        "  listOfTitle = driver.find_elements(By.CLASS_NAME, \"title\")#giving class title to get the titles\n",
        "  listOfReviews = driver.find_elements(By.CLASS_NAME, \"text\")#giving class text to get the text\n",
        "for ele, sub_ele in zip(listOfTitle, listOfReviews):#writing a for loop to append each review and title into the empty arrays created\n",
        "      title_array.append((ele.text).replace('\\n',''))\n",
        "      review_array.append(sub_ele.text)\n",
        "df = pd.DataFrame(list(zip(title_array, review_array)), columns =['Title', 'Review'])\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1098\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Outstanding movie with a haunting performance ...</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Only certain people can relate</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perfect in every aspect.</td>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MASTERPIECE 😍</td>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Hype is real</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>Waiting for Fan Edit</td>\n",
              "      <td>Masterpiece? No. Great? No. Good? Barely.\\n\\nS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>WTF is wrong with the media</td>\n",
              "      <td>Everything that has to be praised has. Joaquin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>A masterpiece</td>\n",
              "      <td>This is one of those once in a lifetime movies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1096</th>\n",
              "      <td>Go watch it with an open mind</td>\n",
              "      <td>I personally loved the movie, you have to go i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>People Severely Missunderstand What This Movie...</td>\n",
              "      <td>Joker is a film about a man's transformation f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1098 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Title                                             Review\n",
              "0     Outstanding movie with a haunting performance ...  Every once in a while a movie comes, that trul...\n",
              "1                        Only certain people can relate  This is a movie that only those who have felt ...\n",
              "2                              Perfect in every aspect.  Truly a masterpiece, The Best Hollywood film o...\n",
              "3                                         MASTERPIECE 😍  Joaquin Phoenix gives a tour de force performa...\n",
              "4                                      The Hype is real  Most of the time movies are anticipated like t...\n",
              "...                                                 ...                                                ...\n",
              "1093                               Waiting for Fan Edit  Masterpiece? No. Great? No. Good? Barely.\\n\\nS...\n",
              "1094                        WTF is wrong with the media  Everything that has to be praised has. Joaquin...\n",
              "1095                                      A masterpiece  This is one of those once in a lifetime movies...\n",
              "1096                      Go watch it with an open mind  I personally loved the movie, you have to go i...\n",
              "1097  People Severely Missunderstand What This Movie...  Joker is a film about a man's transformation f...\n",
              "\n",
              "[1098 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iavfBuCoPKE5"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/). \n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wSce-bUPKE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70edf0db-b2d0-4594-f83a-9248783d5684"
      },
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "with urllib.request.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as filein:\n",
        "    page = filein.read()\n",
        "    soup = BeautifulSoup(page)\n",
        "#     print (soup.prettify())\n",
        "    text2 = soup.p.text\n",
        "    print(text2)\n",
        "    with open('2348407-meta.txt', 'w') as fileou:\n",
        "        json.dump(text2, fileou)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"abstract\":\"Typically, every part in most coherent text has some plausible reason for its presence, some function that it performs to the overall semantics of the text. Rhetorical relations, e.g. contrast, cause, explanation, describe how the parts of a text are linked to each other. Knowledge about this so-called discourse structure has been applied successfully to several natural language processing tasks. This work studies the use of rhetorical relations for Information Retrieval (IR): Is there a correlation between certain rhetorical relations and retrieval performance? Can knowledge about a document's rhetorical relations be useful to IR? We present a language model modification that considers rhetorical relations when estimating the relevance of a document to a query. Empirical evaluation of different versions of our model on TREC settings shows that certain rhetorical relations can benefit retrieval effectiveness notably (>10% in mean average precision over a state-of-the-art baseline).\",\"arxivId\":\"1704.01599\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\",\"url\":\"https://www.semanticscholar.org/author/1784800\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\",\"url\":\"https://www.semanticscholar.org/author/145216927\"},{\"authorId\":null,\"name\":\"Wei Lu\",\"url\":null}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144144799\",\"name\":\"Puneet Mathur\"},{\"authorId\":null,\"name\":\"Rajiv Jain\"},{\"authorId\":\"2075390842\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"2852035\",\"name\":\"Vlad I. Morariu\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.18653/v1/2021.acl-short.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce9e010c5cb2323dfed3af687b12875f01c759bc\",\"title\":\"TIMERS: Document-level Temporal Relation Extraction\",\"url\":\"https://www.semanticscholar.org/paper/ce9e010c5cb2323dfed3af687b12875f01c759bc\",\"venue\":\"ACL/IJCNLP\",\"year\":2021},{\"arxivId\":\"2006.00572\",\"authors\":[{\"authorId\":\"1403693098\",\"name\":\"Erfaneh Gharavi\"},{\"authorId\":\"2024809\",\"name\":\"H. Veisi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"213c505be2cc73343110fd6a41982f0ddaa2d0ee\",\"title\":\"Improve Document Embedding for Text Categorization Through Deep Siamese Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/213c505be2cc73343110fd6a41982f0ddaa2d0ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021071353\",\"name\":\"B. Galitsky\"}],\"doi\":\"10.1007/978-3-030-61641-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91d910139cddd7acd4858dd98ccef72cacdbb644\",\"title\":\"Chatbots for CRM and Dialogue Management\",\"url\":\"https://www.semanticscholar.org/paper/91d910139cddd7acd4858dd98ccef72cacdbb644\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144264304\",\"name\":\"Boris A. Galitsky\"},{\"authorId\":\"1755765\",\"name\":\"Dmitry I. Ilvovsky\"}],\"doi\":\"10.26615/978-954-452-056-4_044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2311b92150c7b10c43d9b59348cc2ccf93da9bf2\",\"title\":\"Discourse-Based Approach to Involvement of Background Knowledge for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2311b92150c7b10c43d9b59348cc2ccf93da9bf2\",\"venue\":\"RANLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8566053\",\"name\":\"Erfaneh Gharavi\"},{\"authorId\":\"83195228\",\"name\":\"R. Silwal\"},{\"authorId\":\"2134075\",\"name\":\"M. Gerber\"},{\"authorId\":\"2024809\",\"name\":\"H. Veisi\"}],\"doi\":\"10.1109/ICOSC.2019.8665662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31c0b55c8ba469874c4fa7b3fd8b70375b1e7421\",\"title\":\"Siamese Discourse Structure Recursive Neural Network for Semantic Representation\",\"url\":\"https://www.semanticscholar.org/paper/31c0b55c8ba469874c4fa7b3fd8b70375b1e7421\",\"venue\":\"2019 IEEE 13th International Conference on Semantic Computing (ICSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1162/coli_a_00360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"710e8c7fa63104ecaf5aee2b898c0c465f82b96d\",\"title\":\"Discourse in Multimedia: A Case Study in Extracting Geometry Knowledge from Textbooks\",\"url\":\"https://www.semanticscholar.org/paper/710e8c7fa63104ecaf5aee2b898c0c465f82b96d\",\"venue\":\"Computational Linguistics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144264304\",\"name\":\"Boris A. Galitsky\"}],\"doi\":\"10.1007/978-3-030-04299-8_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bb0bafea9a8e9ee177ddf6fa116d1b3b9ae9a89\",\"title\":\"Discourse-Level Dialogue Management\",\"url\":\"https://www.semanticscholar.org/paper/7bb0bafea9a8e9ee177ddf6fa116d1b3b9ae9a89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1162/COLI_a_00360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3722832c69a6e6e42fc314ec3feb56e18b5b51f\",\"title\":\"Discourse in Multimedia: A Case Study in Extracting Geometry Knowledge from Textbooks\",\"url\":\"https://www.semanticscholar.org/paper/c3722832c69a6e6e42fc314ec3feb56e18b5b51f\",\"venue\":\"Computational Linguistics\",\"year\":2019},{\"arxivId\":\"1811.05546\",\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56e13ac67e383b80896436122cce5a34617a9513\",\"title\":\"Discourse in Multimedia: A Case Study in Information Extraction\",\"url\":\"https://www.semanticscholar.org/paper/56e13ac67e383b80896436122cce5a34617a9513\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413101320\",\"name\":\"Lin Chuan-An\"},{\"authorId\":\"2611607\",\"name\":\"Hen-Hsen Huang\"},{\"authorId\":\"8157332\",\"name\":\"Zi-Yuan Chen\"},{\"authorId\":\"153924342\",\"name\":\"Hsin-Hsi Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7d77615ace68f881a5db6db50b45cb0f8da465c\",\"title\":\"A Unified RvNN Framework for End-to-End Chinese Discourse Parsing\",\"url\":\"https://www.semanticscholar.org/paper/f7d77615ace68f881a5db6db50b45cb0f8da465c\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"143709239\",\"name\":\"A. Firsov\"}],\"doi\":\"10.1145/3077136.3080720\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19f11641dc8f1ede579ca4e7f212b96d2a8c607f\",\"title\":\"A Metric for Sentence Ordering Assessment Based on Topic-Comment Structure\",\"url\":\"https://www.semanticscholar.org/paper/19f11641dc8f1ede579ca4e7f212b96d2a8c607f\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2072910756\",\"name\":\"V\\u00edctor Flores\"},{\"authorId\":\"2098570488\",\"name\":\"Yahima Hadfeg\"},{\"authorId\":\"2385175\",\"name\":\"C. Villegas\"}],\"doi\":\"10.1007/978-3-319-60837-2_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ec8e675d1ff640e4828e174a54e2beaec3679e6\",\"title\":\"Generating Natural Language Explanations from Knowledge-Based Systems Results, Using Ontology and Discourses Patterns\",\"url\":\"https://www.semanticscholar.org/paper/3ec8e675d1ff640e4828e174a54e2beaec3679e6\",\"venue\":\"IJCRS\",\"year\":2017},{\"arxivId\":\"1703.03640\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"3018458\",\"name\":\"Niels Dalum Hansen\"}],\"doi\":\"10.1016/j.cogsys.2017.03.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"478adb395044b5d9b4039b9a80963b151446cdab\",\"title\":\"A study of metrics of distance and correlation between ranked lists for compositionality detection\",\"url\":\"https://www.semanticscholar.org/paper/478adb395044b5d9b4039b9a80963b151446cdab\",\"venue\":\"Cognitive Systems Research\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5af0f4536f8a98d7e42a40be3fd0e5e51c08d166\",\"title\":\"La structure th\\u00e8me-rh\\u00e8me pour l'ordonnancement de documents en recherche d'information\",\"url\":\"https://www.semanticscholar.org/paper/5af0f4536f8a98d7e42a40be3fd0e5e51c08d166\",\"venue\":\"Document Num\\u00e9rique\",\"year\":2017},{\"arxivId\":\"1709.03742\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ff7f47ef653603b6f65c128627c280ca1026dba\",\"title\":\"Dependencies: Formalising Semantic Catenae for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8ff7f47ef653603b6f65c128627c280ca1026dba\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b9d7421cec8448b0ca96d74cefab96c25d29a1c\",\"title\":\"Short text contextualization in information retrieval : application to tweet contextualization and automatic query expansion. (Contextualisation de textes courts pour la recherche d'information : application \\u00e0 la contextualisation de tweets et \\u00e0 l'expansion automatique de requ\\u00eates)\",\"url\":\"https://www.semanticscholar.org/paper/0b9d7421cec8448b0ca96d74cefab96c25d29a1c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"}],\"doi\":\"10.1109/RCIS.2016.7549352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c4c5d3c9ba58c7e0aadcca70c0771a662ca97dd\",\"title\":\"Document re-ranking based on topic-comment structure\",\"url\":\"https://www.semanticscholar.org/paper/1c4c5d3c9ba58c7e0aadcca70c0771a662ca97dd\",\"venue\":\"2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)\",\"year\":2016},{\"arxivId\":\"1608.00758\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1724314\",\"name\":\"Fabien Tarissan\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"8304471\",\"name\":\"C. Petersen\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"}],\"doi\":\"10.1145/2970398.2970413\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e45b7dbe1f12ea0110fa5bb7609aa90b33c20d9\",\"title\":\"Exploiting the Bipartite Structure of Entity Grids for Document Coherence and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3e45b7dbe1f12ea0110fa5bb7609aa90b33c20d9\",\"venue\":\"ICTIR\",\"year\":2016},{\"arxivId\":\"1610.01327\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"},{\"authorId\":null,\"name\":\"Wei Lu\"},{\"authorId\":\"48356012\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1145/3006299.3006315\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8064f19f6f07e471a5ed84e3e862ab9b0763185a\",\"title\":\"A study of factuality, objectivity and relevance: three desiderata in large-scale information retrieval?\",\"url\":\"https://www.semanticscholar.org/paper/8064f19f6f07e471a5ed84e3e862ab9b0763185a\",\"venue\":\"BDCAT\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"3162238\",\"name\":\"Marion Moulinou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a73852122c71aad778993222766c6f4dd740fd6\",\"title\":\"Analyse des param\\u00e8tres de recherche d'information: Etude de l'influence des param\\u00e8tres sur les r\\u00e9sultats\",\"url\":\"https://www.semanticscholar.org/paper/8a73852122c71aad778993222766c6f4dd740fd6\",\"venue\":\"EGC\",\"year\":2015},{\"arxivId\":\"1507.08234\",\"authors\":[{\"authorId\":\"8304471\",\"name\":\"C. Petersen\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"}],\"doi\":\"10.1145/2808194.2809458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9cb0f457cc8ff9c56b92b96e2e14565feb56552\",\"title\":\"Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR\",\"url\":\"https://www.semanticscholar.org/paper/e9cb0f457cc8ff9c56b92b96e2e14565feb56552\",\"venue\":\"ICTIR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2762285\",\"name\":\"Jos\\u00e9 M. Chenlo\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"2356644\",\"name\":\"D. Losada\"}],\"doi\":\"10.1016/j.datak.2014.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6007af381e860f920fc05401fe826c67c6f2b18a\",\"title\":\"Rhetorical Structure Theory for polarity estimation: An experimental study\",\"url\":\"https://www.semanticscholar.org/paper/6007af381e860f920fc05401fe826c67c6f2b18a\",\"venue\":\"Data Knowl. Eng.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"133998176\",\"name\":\"Gonz\\u00e1lez Chenlo\"},{\"authorId\":\"143697792\",\"name\":\"J. Manuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd2426c0f4fd14a2a061662a2074b52bcd3f06bb\",\"title\":\"Exploiting multiple sources of evidence for opinion search in the web\",\"url\":\"https://www.semanticscholar.org/paper/bd2426c0f4fd14a2a061662a2074b52bcd3f06bb\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14201699\",\"name\":\"Sungbin Choi\"},{\"authorId\":\"4273555\",\"name\":\"Jinwook Choi\"},{\"authorId\":\"34786903\",\"name\":\"Sooyoung Yoo\"},{\"authorId\":\"2108878965\",\"name\":\"Heechun Kim\"},{\"authorId\":\"2110076700\",\"name\":\"Youngho Lee\"}],\"doi\":\"10.1016/j.jbi.2013.08.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7181bd11fa61899b3ccd4c7f527de0eb6244913\",\"title\":\"Semantic concept-enriched dependence model for medical information retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c7181bd11fa61899b3ccd4c7f527de0eb6244913\",\"venue\":\"J. Biomed. Informatics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48969078\",\"name\":\"W. Drijfhout\"},{\"authorId\":\"2327920\",\"name\":\"O. Jundt\"},{\"authorId\":\"2911513\",\"name\":\"L. Wevers\"},{\"authorId\":\"1691929\",\"name\":\"D. Hiemstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ca1c847a200f46c969261d3686f7be136c7bef\",\"title\":\"Traitor: Associating Concepts using the World Wide Web\",\"url\":\"https://www.semanticscholar.org/paper/10ca1c847a200f46c969261d3686f7be136c7bef\",\"venue\":\"DIR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127495\",\"name\":\"Fawaz Alarfaj\"},{\"authorId\":\"2993548\",\"name\":\"Udo Kruschwitz\"},{\"authorId\":\"144251978\",\"name\":\"C. Fox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3aa86dcc5c2b83e7a39481dd729f07e9eb90c87c\",\"title\":\"An Adaptive Window-Size Approach for Expert-Finding\",\"url\":\"https://www.semanticscholar.org/paper/3aa86dcc5c2b83e7a39481dd729f07e9eb90c87c\",\"venue\":\"DIR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34805599\",\"name\":\"Kurt Englmeier\"},{\"authorId\":\"35263108\",\"name\":\"J. Atkinson\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"48821339\",\"name\":\"F. Murtagh\"},{\"authorId\":\"145433861\",\"name\":\"J. Pereira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c844ff5f73186762d70cfa0247ffd90ac582860\",\"title\":\"Open Archive TOULOUSE Archive Ouverte (OATAO)\",\"url\":\"https://www.semanticscholar.org/paper/3c844ff5f73186762d70cfa0247ffd90ac582860\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2762285\",\"name\":\"Jos\\u00e9 M. Chenlo\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"2356644\",\"name\":\"D. Losada\"}],\"doi\":\"10.1007/978-3-642-38824-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5550303aab415c066964738e32bc7076209ba4ad\",\"title\":\"Sentiment-Based Ranking of Blog Posts Using Rhetorical Structure Theory\",\"url\":\"https://www.semanticscholar.org/paper/5550303aab415c066964738e32bc7076209ba4ad\",\"venue\":\"NLDB\",\"year\":2013}],\"corpusId\":7087061,\"doi\":\"10.1145/2348283.2348407\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"isOpenAccess\":true,\"isPublisherLicensed\":true,\"is_open_access\":true,\"is_publisher_licensed\":true,\"numCitedBy\":28,\"numCiting\":40,\"paperId\":\"4c64daac9dda2920752e9a2b0333abe3e02f4beb\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695153\",\"name\":\"W. Mann\"},{\"authorId\":\"20082155\",\"name\":\"S. A. Thompson\"}],\"doi\":\"10.1515/text.1.1988.8.3.243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af5100605a3b6bfd0adf9a30e69a47d1b98340ba\",\"title\":\"Rhetorical Structure Theory: Toward a functional theory of text organization\",\"url\":\"https://www.semanticscholar.org/paper/af5100605a3b6bfd0adf9a30e69a47d1b98340ba\",\"venue\":\"\",\"year\":1988},{\"arxivId\":\"1302.6782\",\"authors\":[{\"authorId\":\"1406721516\",\"name\":\"Adriano Azevedo-Filho\"},{\"authorId\":\"2932960\",\"name\":\"R. Shachter\"}],\"doi\":\"10.1016/B978-1-55860-332-5.50009-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d7a296a0b0210be84934120396a41b7f7b2c25f\",\"title\":\"Laplace's Method Approximations for Probabilistic Inference in Belief Networks with Continuous Variables\",\"url\":\"https://www.semanticscholar.org/paper/7d7a296a0b0210be84934120396a41b7f7b2c25f\",\"venue\":\"UAI\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34938639\",\"name\":\"W. A. Gale\"},{\"authorId\":\"3215185\",\"name\":\"G. Sampson\"}],\"doi\":\"10.1080/09296179508590051\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cddeb5149f4de157d4daeb609a8b1432a8126e7b\",\"title\":\"Good-Turing Frequency Estimation Without Tears\",\"url\":\"https://www.semanticscholar.org/paper/cddeb5149f4de157d4daeb609a8b1432a8126e7b\",\"venue\":\"J. Quant. Linguistics\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749837\",\"name\":\"Eugene Charniak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d5e3fa888bee872b7adb7fa810089aa8ab1d58\",\"title\":\"A Maximum-Entropy-Inspired Parser\",\"url\":\"https://www.semanticscholar.org/paper/76d5e3fa888bee872b7adb7fa810089aa8ab1d58\",\"venue\":\"ANLP\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793218\",\"name\":\"D. Gildea\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.3115/1075218.1075283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c274b8aac56e49e65a3827c570b2496b14429166\",\"title\":\"Automatic Labeling of Semantic Roles\",\"url\":\"https://www.semanticscholar.org/paper/c274b8aac56e49e65a3827c570b2496b14429166\",\"venue\":\"ACL\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12303693\",\"name\":\"Lynn Carlson\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"},{\"authorId\":\"7424872\",\"name\":\"Mary Ellen Okurovsky\"}],\"doi\":\"10.3115/1118078.1118083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07a78850c0c2ff11acf21fccca40bfcb79da282b\",\"title\":\"Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory\",\"url\":\"https://www.semanticscholar.org/paper/07a78850c0c2ff11acf21fccca40bfcb79da282b\",\"venue\":\"SIGDIAL Workshop\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"2352980\",\"name\":\"T. Rath\"},{\"authorId\":\"2709427\",\"name\":\"Fangfang Feng\"}],\"doi\":\"10.1145/383952.384005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67cb24c172b66b2d14f066a1f02ce57a22a075a1\",\"title\":\"Modeling score distributions for combining the outputs of search engines\",\"url\":\"https://www.semanticscholar.org/paper/67cb24c172b66b2d14f066a1f02ce57a22a075a1\",\"venue\":\"SIGIR '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2480901\",\"name\":\"S. Teufel\"},{\"authorId\":\"2085030\",\"name\":\"M. Moens\"}],\"doi\":\"10.1162/089120102762671936\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54eafbf7621337724c6591cc13e604986243293a\",\"title\":\"Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status\",\"url\":\"https://www.semanticscholar.org/paper/54eafbf7621337724c6591cc13e604986243293a\",\"venue\":\"Computational Linguistics\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2768186\",\"name\":\"K. J\\u00e4rvelin\"},{\"authorId\":\"2732839\",\"name\":\"Jaana Kek\\u00e4l\\u00e4inen\"}],\"doi\":\"10.1145/582415.582418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8490234d79b47e459824dcf87c1e288211a3c964\",\"title\":\"Cumulated gain-based evaluation of IR techniques\",\"url\":\"https://www.semanticscholar.org/paper/8490234d79b47e459824dcf87c1e288211a3c964\",\"venue\":\"TOIS\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912454\",\"name\":\"C. Fillmore\"},{\"authorId\":\"1749194\",\"name\":\"C. Baker\"},{\"authorId\":\"153515478\",\"name\":\"H. Sato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87834ded1d151355d2028dc6efb26fcaa48ab9fc\",\"title\":\"The FrameNet Database and Software Tools\",\"url\":\"https://www.semanticscholar.org/paper/87834ded1d151355d2028dc6efb26fcaa48ab9fc\",\"venue\":\"LREC\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736467\",\"name\":\"ChengXiang Zhai\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":\"10.1145/564376.564387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"decf799682a402b9ee50b9d6c0267f6c545a7031\",\"title\":\"Two-stage language models for information retrieval\",\"url\":\"https://www.semanticscholar.org/paper/decf799682a402b9ee50b9d6c0267f6c545a7031\",\"venue\":\"SIGIR '02\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144156677\",\"name\":\"Paul Kingsbury\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc090a68e45e0e6337136777d21c87b76a90ae72\",\"title\":\"From TreeBank to PropBank\",\"url\":\"https://www.semanticscholar.org/paper/fc090a68e45e0e6337136777d21c87b76a90ae72\",\"venue\":\"LREC\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"}],\"doi\":\"10.3115/1073445.1073475\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b3858c0c31c6f0826c891a42367671f6e76d46c\",\"title\":\"Sentence Level Discourse Parsing using Syntactic and Lexical Information\",\"url\":\"https://www.semanticscholar.org/paper/0b3858c0c31c6f0826c891a42367671f6e76d46c\",\"venue\":\"NAACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":\"10.1007/978-94-017-0171-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b71ead55fd6520dd4604de66cbb732bc2b7a6070\",\"title\":\"Language Modeling for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b71ead55fd6520dd4604de66cbb732bc2b7a6070\",\"venue\":\"The Springer International Series on Information Retrieval\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12294213\",\"name\":\"J. Morato\"},{\"authorId\":\"3028529\",\"name\":\"J. Morillo\"},{\"authorId\":\"1805316\",\"name\":\"Gonzalo G\\u00e9nova\"},{\"authorId\":\"31513219\",\"name\":\"Jos\\u00e9 A. Moreiro\"}],\"doi\":\"10.1016/S0306-4573(02)00081-X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb38a830255783ad3f0824d15f178dd03e5e2be2\",\"title\":\"Experiments in discourse analysis impact on information classification and retrieval algorithms\",\"url\":\"https://www.semanticscholar.org/paper/cb38a830255783ad3f0824d15f178dd03e5e2be2\",\"venue\":\"Inf. Process. Manag.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144009691\",\"name\":\"Chris Buckley\"},{\"authorId\":\"1746656\",\"name\":\"E. Voorhees\"}],\"doi\":\"10.1145/1008992.1009000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6878cdc5b632e018f827a9d1520e7353d8502d25\",\"title\":\"Retrieval evaluation with incomplete information\",\"url\":\"https://www.semanticscholar.org/paper/6878cdc5b632e018f827a9d1520e7353d8502d25\",\"venue\":\"SIGIR '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49370744\",\"name\":\"D. Y. Wang\"},{\"authorId\":\"1752375\",\"name\":\"R. Luk\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"},{\"authorId\":\"145219946\",\"name\":\"K. Kwok\"}],\"doi\":\"10.1007/11765448_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6dcfcc8c5486859d78e317896abad0c4314442c\",\"title\":\"An Information Retrieval Approach Based on Discourse Type\",\"url\":\"https://www.semanticscholar.org/paper/e6dcfcc8c5486859d78e317896abad0c4314442c\",\"venue\":\"NLDB\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46611104\",\"name\":\"M. Sun\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":\"10.1016/j.knosys.2007.04.005\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"525867ebf15c535305f18eeb12b41b5d71168abf\",\"title\":\"Discourse processing for context question answering based on linguistic knowledge\",\"url\":\"https://www.semanticscholar.org/paper/525867ebf15c535305f18eeb12b41b5d71168abf\",\"venue\":\"Knowl. Based Syst.\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30184027\",\"name\":\"B. Webber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"31793f9f959ac175632407ab0d9b7bda0e32f6f3\",\"title\":\"Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2\",\"url\":\"https://www.semanticscholar.org/paper/31793f9f959ac175632407ab0d9b7bda0e32f6f3\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2800288\",\"name\":\"David duVerle\"},{\"authorId\":\"2356111\",\"name\":\"H. Prendinger\"}],\"doi\":\"10.3115/1690219.1690239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cc84d84ad87b9a1f6496fb4acbbc758a9be6345\",\"title\":\"A Novel Discourse Parser Based on Support Vector Machine Classification\",\"url\":\"https://www.semanticscholar.org/paper/7cc84d84ad87b9a1f6496fb4acbbc758a9be6345\",\"venue\":\"ACL\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059584\",\"name\":\"Swapna Somasundaran\"},{\"authorId\":\"1686834\",\"name\":\"Galileo Namata\"},{\"authorId\":\"144120827\",\"name\":\"J. Wiebe\"},{\"authorId\":\"1746034\",\"name\":\"L. Getoor\"}],\"doi\":\"10.3115/1699510.1699533\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bd67cc94aa20fec80b205ee75517a4f194adc9c\",\"title\":\"Supervised and Unsupervised Methods in Employing Discourse Relations for Improving Opinion Polarity Classification\",\"url\":\"https://www.semanticscholar.org/paper/9bd67cc94aa20fec80b205ee75517a4f194adc9c\",\"venue\":\"EMNLP\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756567\",\"name\":\"L. Yu\"},{\"authorId\":\"1681512\",\"name\":\"Chung-Hsien Wu\"},{\"authorId\":\"3008622\",\"name\":\"F. Jang\"}],\"doi\":\"10.1016/j.artint.2008.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfcb90cda0999a56a6d13bcac84f12adf0d2436\",\"title\":\"Psychiatric document retrieval using a discourse-aware model\",\"url\":\"https://www.semanticscholar.org/paper/cbfcb90cda0999a56a6d13bcac84f12adf0d2436\",\"venue\":\"Artif. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2160529\",\"name\":\"Daniel Tunkelang\"},{\"authorId\":\"1701298\",\"name\":\"M. Thelwall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d07576c370cc6ef48f9268714b4fd1c75b226ef5\",\"title\":\"Synthesis Lectures on Information Concepts, Retrieval, and Services\",\"url\":\"https://www.semanticscholar.org/paper/d07576c370cc6ef48f9268714b4fd1c75b226ef5\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689089\",\"name\":\"M. Smucker\"},{\"authorId\":\"144890574\",\"name\":\"James Allan\"},{\"authorId\":\"1750995\",\"name\":\"Ben Carterette\"}],\"doi\":\"10.1145/1571941.1572050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e38cde98f2e2012ee848bab4a3c964624783be7d\",\"title\":\"Agreement among statistical significance tests for information retrieval evaluation at varying sample sizes\",\"url\":\"https://www.semanticscholar.org/paper/e38cde98f2e2012ee848bab4a3c964624783be7d\",\"venue\":\"SIGIR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39055225\",\"name\":\"J. Wang\"},{\"authorId\":\"39522749\",\"name\":\"Jianhan Zhu\"}],\"doi\":\"10.1145/1835449.1835489\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b6e6f0187f2cd44eeca1b80da464562357b20a\",\"title\":\"On statistical analysis and optimization of information retrieval effectiveness metrics\",\"url\":\"https://www.semanticscholar.org/paper/34b6e6f0187f2cd44eeca1b80da464562357b20a\",\"venue\":\"SIGIR\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50649676\",\"name\":\"J. Clarke\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1162/coli_a_00004\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"6c95908d08323c5acfc5bfdf7399f31563ade4f5\",\"title\":\"Discourse Constraints for Document Compression\",\"url\":\"https://www.semanticscholar.org/paper/6c95908d08323c5acfc5bfdf7399f31563ade4f5\",\"venue\":\"CL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767336\",\"name\":\"Annie Louis\"},{\"authorId\":\"1714374\",\"name\":\"A. Joshi\"},{\"authorId\":\"3115414\",\"name\":\"A. Nenkova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b88876344be6d9a8172f72bc0a836994f6b6f719\",\"title\":\"Discourse indicators for content selection in summarization\",\"url\":\"https://www.semanticscholar.org/paper/b88876344be6d9a8172f72bc0a836994f6b6f719\",\"venue\":\"SIGDIAL Conference\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9106864\",\"name\":\"Nipun Suwandaratna\"},{\"authorId\":\"39630485\",\"name\":\"U. Perera\"}],\"doi\":\"10.1109/ICIAFS.2010.5715646\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c43f79ab60afc1e2bc3859365c120eb11bd0bbd7\",\"title\":\"Discourse marker based topic identification and search results refining\",\"url\":\"https://www.semanticscholar.org/paper/c43f79ab60afc1e2bc3859365c120eb11bd0bbd7\",\"venue\":\"2010 Fifth International Conference on Information and Automation for Sustainability\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1815447\",\"name\":\"Michael Bendersky\"},{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1891854\",\"name\":\"Y. Diao\"}],\"doi\":\"10.1145/1935826.1935849\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08c34883743406f05a10c54c802373997c706ce7\",\"title\":\"Quality-biased ranking of web documents\",\"url\":\"https://www.semanticscholar.org/paper/08c34883743406f05a10c54c802373997c706ce7\",\"venue\":\"WSDM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893187\",\"name\":\"Eyal Krikon\"},{\"authorId\":\"1779654\",\"name\":\"Oren Kurland\"}],\"doi\":\"10.1007/s10791-011-9168-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"278f55438b8fa2eb3cea6a120d48ea1f8b8b07f9\",\"title\":\"A study of the integration of passage-, document-, and cluster-based information for re-ranking search results\",\"url\":\"https://www.semanticscholar.org/paper/278f55438b8fa2eb3cea6a120d48ea1f8b8b07f9\",\"venue\":\"Information Retrieval\",\"year\":2011},{\"arxivId\":\"1004.5168\",\"authors\":[{\"authorId\":\"3114123\",\"name\":\"G. Cormack\"},{\"authorId\":\"1689089\",\"name\":\"M. Smucker\"},{\"authorId\":\"1751287\",\"name\":\"C. Clarke\"}],\"doi\":\"10.1007/s10791-011-9162-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38612e346fdf3158c32c16058f7e8820a8f0325e\",\"title\":\"Efficient and effective spam filtering and re-ranking for large web datasets\",\"url\":\"https://www.semanticscholar.org/paper/38612e346fdf3158c32c16058f7e8820a8f0325e\",\"venue\":\"Information Retrieval\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"144871732\",\"name\":\"A. Lopez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"889b2925ae0966585b8da6f678526bbdd99da592\",\"title\":\"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/889b2925ae0966585b8da6f678526bbdd99da592\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801153\",\"name\":\"Bas Heerschop\"},{\"authorId\":\"2373094\",\"name\":\"F. Goossen\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"1729599\",\"name\":\"F. Frasincar\"},{\"authorId\":\"1678244\",\"name\":\"U. Kaymak\"},{\"authorId\":\"144097974\",\"name\":\"F. D. Jong\"}],\"doi\":\"10.1145/2063576.2063730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ba847377b1667add27eb9663aa847b53c59f9aa\",\"title\":\"Polarity analysis of texts using discourse structure\",\"url\":\"https://www.semanticscholar.org/paper/9ba847377b1667add27eb9663aa847b53c59f9aa\",\"venue\":\"CIKM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2718039\",\"name\":\"Christos Christodoulopoulos\"},{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"},{\"authorId\":\"145332819\",\"name\":\"Mark Steedman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6b2694d5606a0bbab63c4c470b20f1b754df9ff\",\"title\":\"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL\",\"url\":\"https://www.semanticscholar.org/paper/a6b2694d5606a0bbab63c4c470b20f1b754df9ff\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48169566\",\"name\":\"L. Wang\"},{\"authorId\":\"5571580\",\"name\":\"Marco Lui\"},{\"authorId\":\"1736741380\",\"name\":\"Su Nam Kim\"},{\"authorId\":\"1720988\",\"name\":\"Joakim Nivre\"},{\"authorId\":\"145465286\",\"name\":\"Timothy Baldwin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d471854ae1705a5e4f6df60ec8fb602c6e88b673\",\"title\":\"Predicting Thread Discourse Structure over Technical Web Forums\",\"url\":\"https://www.semanticscholar.org/paper/d471854ae1705a5e4f6df60ec8fb602c6e88b673\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701219\",\"name\":\"Sucheta Ghosh\"},{\"authorId\":\"145341661\",\"name\":\"Richard Johansson\"},{\"authorId\":\"1719162\",\"name\":\"G. Riccardi\"},{\"authorId\":\"1809243\",\"name\":\"Sara Tonelli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2b168dbaa57736b31891451163a5c5582d84324\",\"title\":\"Shallow Discourse Parsing with Conditional Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/e2b168dbaa57736b31891451163a5c5582d84324\",\"venue\":\"IJCNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2204295\",\"name\":\"Lanjun Zhou\"},{\"authorId\":\"1707937\",\"name\":\"Binyang Li\"},{\"authorId\":\"145816335\",\"name\":\"Wei Gao\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"1784988\",\"name\":\"Kam-Fai Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5cb9f31922d4381a8b326b9cd9cbdacf744907c\",\"title\":\"Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities\",\"url\":\"https://www.semanticscholar.org/paper/e5cb9f31922d4381a8b326b9cd9cbdacf744907c\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36717818\",\"name\":\"A. Davison\"}],\"doi\":\"10.1007/978-1-4614-6170-8_100159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1be08088b4ca2a3d214cbbb325fbde30c334a77e\",\"title\":\"Statistical Models\",\"url\":\"https://www.semanticscholar.org/paper/1be08088b4ca2a3d214cbbb325fbde30c334a77e\",\"venue\":\"Encyclopedia of Social Network Analysis and Mining\",\"year\":2014}],\"title\":\"Rhetorical relations for information retrieval\",\"topics\":[{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Linker (computing)\",\"topicId\":\"25565\",\"url\":\"https://www.semanticscholar.org/topic/25565\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"}],\"url\":\"https://www.semanticscholar.org/paper/4c64daac9dda2920752e9a2b0333abe3e02f4beb\",\"venue\":\"SIGIR '12\",\"year\":2012}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElkHUsmkPKE6"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NRMSSpPKE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77618bff-2041-4f41-f558-4ca6ee4e0280"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apWkzYIML2jo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tweepy #for extract data from twitter we use tweepy\n",
        "from tweepy import OAuthHandler #validates your account and connects to twitter"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxtlKdMPL4UH"
      },
      "source": [
        "consumer_key =\"2Em7SxlX9jPMfL4x97r3zMO0x\"#these are username and password to our twitter account\n",
        "consumer_secret = \"sVbJzekKuiAgq83Y7gCwNVbSowqQokGVzWexKHl2cXIPceWtSd\"\n",
        "access_token =\"1439767876962029572-uUMt8oWRyzj9ilE5zk4uYbL93sCMPT\"\n",
        "access_token_secret = \"oydIGymn9bS767FVEMawE9GyGAnMmBJfaY2XXKmHnmliF\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g98S2D2RQrih"
      },
      "source": [
        "#calling API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynakjen0OXKI"
      },
      "source": [
        "username ='KamalaHarris'\n",
        "count = 1000"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ol_lI2WHMC2a",
        "outputId": "60ed1325-cf63-48f2-e5ac-d2c8b71a0372"
      },
      "source": [
        "try:     \n",
        " # Creation of query method using parameters\n",
        " tweets = tweepy.Cursor(api.user_timeline,id=username).items(count)\n",
        " \n",
        " # Pulling information from tweets iterable object\n",
        " tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        " \n",
        " # Creation of dataframe from tweets list\n",
        " # Add or remove columns as you remove tweet information\n",
        " tweets_df = pd.DataFrame(tweets_list)\n",
        "except BaseException as e:\n",
        "      print('failed on_status,',str(e))\n",
        "      time.sleep(3)\n",
        "tweets_df.columns=['posted time','user_id','text']\n",
        "tweets_df"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posted time</th>\n",
              "      <th>user_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-29 23:35:00</td>\n",
              "      <td>1443358682096574467</td>\n",
              "      <td>We can build an economy that gives working peo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-09-29 21:37:44</td>\n",
              "      <td>1443329169082011653</td>\n",
              "      <td>We have an opportunity to prove to the America...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-09-29 01:13:00</td>\n",
              "      <td>1443020955819851776</td>\n",
              "      <td>Our Build Back Better Agenda will lower health...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-09-28 23:56:00</td>\n",
              "      <td>1443001579066511363</td>\n",
              "      <td>Our democracy is strongest when everyone parti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-09-28 16:55:20</td>\n",
              "      <td>1442895714950938627</td>\n",
              "      <td>The right to vote in free and fair elections, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2020-10-28 15:00:02</td>\n",
              "      <td>1321466764220194816</td>\n",
              "      <td>Food represents a piece of where we came from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>2020-10-28 13:43:04</td>\n",
              "      <td>1321447392680595460</td>\n",
              "      <td>Future generations are counting on us to get t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>2020-10-28 02:32:37</td>\n",
              "      <td>1321278669210456065</td>\n",
              "      <td>Today we honor the memory of the eleven worshi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>2020-10-28 01:56:19</td>\n",
              "      <td>1321269535002005505</td>\n",
              "      <td>Thank you, Nevada! Let’s get this done in seve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>2020-10-28 00:38:18</td>\n",
              "      <td>1321249899766185984</td>\n",
              "      <td>We’re only a few days away from the most impor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            posted time  ...                                               text\n",
              "0   2021-09-29 23:35:00  ...  We can build an economy that gives working peo...\n",
              "1   2021-09-29 21:37:44  ...  We have an opportunity to prove to the America...\n",
              "2   2021-09-29 01:13:00  ...  Our Build Back Better Agenda will lower health...\n",
              "3   2021-09-28 23:56:00  ...  Our democracy is strongest when everyone parti...\n",
              "4   2021-09-28 16:55:20  ...  The right to vote in free and fair elections, ...\n",
              "..                  ...  ...                                                ...\n",
              "995 2020-10-28 15:00:02  ...  Food represents a piece of where we came from ...\n",
              "996 2020-10-28 13:43:04  ...  Future generations are counting on us to get t...\n",
              "997 2020-10-28 02:32:37  ...  Today we honor the memory of the eleven worshi...\n",
              "998 2020-10-28 01:56:19  ...  Thank you, Nevada! Let’s get this done in seve...\n",
              "999 2020-10-28 00:38:18  ...  We’re only a few days away from the most impor...\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}